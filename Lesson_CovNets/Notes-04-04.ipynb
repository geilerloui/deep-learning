{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[backpropagation in CNN](https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/)\n",
    "\n",
    "Les CNN partent de trois idées:\n",
    "* Local receptive Fields - un seul problème dans son exemple, on a pas la profondeur (pixels trois couleurs il faut rajouter, c'est la où on introduit les tenseurs)\n",
    "* Shared Weights and Biases: le parameter sharing fait qu'il y'a une propriété appelé **equivariance** to translation.\n",
    "* Pooling\n",
    "\n",
    "> On peut rajouter aussi l'opération de convolution vs cross-corrélation et explication de comment ça marche\n",
    "\n",
    "### Local Receptive Fields\n",
    "\n",
    "Dans le modèle classique du Feed forward neural network, chacun des pixel était connecté à tout les noeuds de la couche câché. À la place en CNN, nous ferons uniquement des petites connexions, dans des régions localisés de l'image d'entré.\n",
    "\n",
    "Pour être plus précis, chaque neurone dans la première couche câché sera connecté à une petite région des neurones d'entré, par exemple, une région de taille 5x5, correspondant à 25 pixels ressemblera à ça\n",
    "\n",
    "IMAGE\n",
    "\n",
    "Cette région dans l'image d'entré est appelé **local receptive field (LRF)** pour la couche câché. On va ensuite déplacer ce champ sur toute l'image.\n",
    "\n",
    "IMAGE 1 et 2\n",
    "\n",
    "Et donc Si on a une image de taille $28\\times 28$, et un LRF $5 \\times 5$, on aura alors $24 \\times 24$ neurones dans la couche câché.\n",
    "\n",
    "Dans l'exemple qu'on a vu on ne se déplace que d'un pixel à la fois. C'est ce qu'on appelle le **stride** (le pas), on pourrait passer à 2 pixels à la fois...\n",
    "\n",
    "ADD formule de calcul pour la taille des neurones câchés.\n",
    "\n",
    "W = 28, H = 28, S=1, F=5, P=0\n",
    "\n",
    "### Shared Weights and Biases - \" Sparse Weight \"\n",
    "\n",
    "Il dit que chaque couche câché a un biais et une matrice des poids $5\\times 5$ connecté au LRF. Ce qu'il n'a pas précisé est qu'on va utiliser les mêmes poids et biais pour chacun des $24 \\times 24$ neurones câchés.\n",
    "\n",
    "\n",
    "Dans le cas une dimension: il fait la comparaison entre la matrice des poids du FFNN,\n",
    "\n",
    "\\begin{pmatrix} \n",
    "W_{0,0} & W_{0,1} & W_{0,2} & W_{0,3} & ... \\\\\n",
    "W_{1,0} & W_{1,1} & W_{1,2} & W_{1,3} & ... \\\\\n",
    "W_{2,0} & 0 & w_0 & w_1 & ... \\\\\n",
    "0 & 0 & 0 & w_0 & ... \\\\\n",
    "... & ... & ... & ... & ...\n",
    "\\end{pmatrix}\n",
    "\n",
    "et la matrice creuse qu'on a lorsque les poids sont partagés\n",
    "\n",
    "\\begin{pmatrix} \n",
    "w_0 & w_1 & 0 & 0 & ... \\\\\n",
    "0 & w_0 & w_1 & 0 & ... \\\\\n",
    "0 & 0 & w_0 & w_1 & ... \\\\\n",
    "0 & 0 & 0 & w_0 & ... \\\\\n",
    "... & ... & ... & ... & ...\n",
    "\\end{pmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "biblio:\n",
    "* http://colah.github.io/posts/2014-07-Understanding-Convolutions/\n",
    "* http://neuralnetworksanddeeplearning.com/chap6.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
