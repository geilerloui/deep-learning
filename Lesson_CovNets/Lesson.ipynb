{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations of Fully Connected Networks\n",
    "\n",
    "IMAGE\n",
    "\n",
    "On peut se demander le nombre de paramètre que va avoir un Perceptron à une couche câché.  \n",
    "On arrive à $28,326$ paramètres.\n",
    "\n",
    "IMAGE\n",
    "\n",
    "Si on considère des images actuelles, $1000 \\times 1000$ pixels, on va avoir du $10^6$ neurones en sortie, et du 10^12 en nombres de paramètres\n",
    "> On arrive sur une explosition du nombre de paramètre pour une seule couche câché\n",
    "\n",
    "Notion de structure locale, dans tout les signaux bas niveau, image, son... la structure locale est importante\n",
    "* Signaux 1D: Pour du son, la détection des phonèmes vont apparaitre localement avec des bandes de fréquencs\n",
    "* Signaux 2D: Comme les images, pour un chat, il y'a un arrangement spatial spécifique.\n",
    "\n",
    "On a prit la BDD MNIST, auquel on a fait une permutation des pixels (en rouge), ce qui prouve bien que pour nous humains l'aspect local de l'image est important. Cependant, **pour le réseaux ces deux images sont équivalentes**.\n",
    "\n",
    "--\n",
    "\n",
    "Reconnaissance de forme: on veut reconnaitre des rectangles, triangles, étoiles et losanges. On voit bien que la couleur ne permet pas de prédire les différentes formes. \n",
    "> Avec des connaissances à priori, comme le faite que la couleur n'est pas importante, on peut passer l'image en niveau de gris. Ce qui permettrait d'apprendre avec moins d'exemples et d'éviter le surapprentissage.\n",
    "\n",
    "----\n",
    "\n",
    "On va avoir deux attentes:\n",
    "* Pour de petite déformation $\\Rightarrow$ on a des représentations similaires\n",
    "* Pour de grande déformation $\\Rightarrow$ elles seront très différentes\n",
    "\n",
    "Or, avec le FNN, on n'aura cette différence, on peut voir que pour une modification de deux pixels vers la droite, le vecteur des pixels va être différents\n",
    "\n",
    "> Limite: Les problèmes d'invariances et stabilité des représentations. Comme des transformations d'échelles, de rotation, déformations etc.\n",
    "\n",
    "----\n",
    "\n",
    "Ils vont permettre de réduire les paramètres, explicitement modéliser la structure locale, gagner de l'invariance pour les déformations locale et on pourra toujours utiliser la rétropropagation de l'erreur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution\n",
    "\n",
    "Nous allons présenter l'opérateur de convolution pour les signaux 1D et 2D.\n",
    "\n",
    "IMG\n",
    "\n",
    "On va le définir avec un **filtre à réponse impulsionnel finie** (vocabulaire traitement du signal) définie par une taille **d** impaire.\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "On utilise toujours les **filtre à réponse impulsionnel finie**, \n",
    "\n",
    "1. On peut le lire comme: on applique une rotation par rapport à son centre de h ce qui va donner le filte g. A partir de ce filtre symétrisé, en supperposant les valeurs on aura f' en sortie. A partir de ce filtre g symétrisé on calcule simplement, en superposant les coefficients du masque avec les valeurs des niveaux de gris de l'image, pour donner la valeur filtré f' en sortie\n",
    "\n",
    "\n",
    "-----\n",
    "Cette convolution a un lien fort avec la Cross-correlation (corrélation croisée i.e. une convolution pour lequel on n'a pas symétrisé le masque)\n",
    "\n",
    "La convolution par h donnera un résultat f' qui va être la même que la corrélation croisée avec le masque g. \n",
    "\n",
    "image: pour chaque pixel il faut superposer les coefficients du masque à l'image et calculer une somme pondéré\n",
    "\n",
    "----\n",
    "\n",
    "Cette corrélation croisée s'interpréte aussi comme un produit scalaire pour chacun des pixels de l'image filtrée, entre les pixels de la région de l'image et les coefficients du filtre.  \n",
    "Des grandes valeurs lors de l'image filtré (f'(i,j)) ça va indiquer que les coefficients du filtre et les valeurs des niveaux de gris de l'image sont alignés, au sens du produit scalaire. Ils ont une forte valeeur.\n",
    "\n",
    "-----\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "----\n",
    "Pour l'instant on a parlé uniquement d'une convolution avec une image en input et une en output et où on se déplaçait d'un pixel à chaque fois --> Ces deux images avaient la même taille modulo les effets de bord.\n",
    "\n",
    "\"Strided convolution\" = convolution avec pas; permet d'avoir a la sortie qui sont plus petite, ce qui est intéreessant en terme de mémoire. dans l'image on a un stride de 2.\n",
    "\n",
    "---\n",
    "Pour approximer le gradient on peut utiliser des masques de Sobel (M_x)\n",
    "\n",
    "On note le premier I_x, il va calculer des valeurs à droite moins des valeurs à gauche; il va servrir à détecter les gradients dans l'axe des x (c'est pour ça qu'on le note I_x)\n",
    "\n",
    "-----\n",
    "\n",
    "On peut voir l'opération de contours comme une opération de convolution suivi d'un seuillage\n",
    "\n",
    "----\n",
    "\n",
    "La convolution est un opérateur linéaire, on peut le voir comme un produit matriciel. \n",
    "\n",
    "y = W . x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Properties\n",
    "\n",
    "On va voir ce qui fait l'intérêt des réseaux convolutionel par rapport à complétement connectés.\n",
    "\n",
    "Deux aspects dans le calcul de la convolution permettent une diminution du nb de paramètres:\n",
    "1. On a des connexions sparse: une neurone va avoir un sous-ensemble de pixels\n",
    "2. poids partagés, à chaque position de l'image on va avoir le même jeu de poids, si on a un masque de taille 10x10 on est passé à 100 paramètres;\n",
    "--> avec le filtrage le nombre de paramètre est indépendant de la taille de l'image (ça dépendent, uniquement de la taille de l'image)\n",
    "\n",
    "partage des poids = les même features sont détectés sur toute l'image, ce qui fait sens, lorsqu'eon cherche différentes voiture à différents endroits de l'image.\n",
    "\n",
    "----\n",
    "Structure local spatiale: ce qu'on avait vu\n",
    "\n",
    "---\n",
    "Propriété d'équivariance, si f et g commutent, \n",
    "la convolution et équivariant à la translation, donc si on prends l'image d'entré (X) avec g on lui fait convoluer avec h, ce qui est le même que si on avait fait une translation (f)\n",
    "\n",
    "----\n",
    "\n",
    "---\n",
    "\n",
    "il va être important de mélanger des linéarité et non linéarité. surtout dans les réseaux profonds. \n",
    "Si on fait suivre la convolution par une non-linéarité, on va pouvoir faire ressortir des contours de l'image qui sont important (les deux images en noir à droite)\n",
    "\n",
    "-----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Aggrégation dans les réseaux convolutifs, pour la robustesse aux déformations locales ou stabilités.\n",
    "\n",
    "Le pooling est une aggrégation, moyennage statistique d'un ensemble de valeur\n",
    "\n",
    "son but est d'avoir des statistiques globales (max, min mean...), en étant invariant, \n",
    "\n",
    "----\n",
    "\n",
    "l_p pooling généralise les max, min ... il assure une transition entre un pooling moyenne lorsque p=1, et un max lorsque p tend vers l'infinie\n",
    "\n",
    "-----\n",
    "\n",
    "comment ce pooling va s'intégrer dans les réseaux convolutifs, on veut une aggrégation spatiale, i.e. sur des régions de l'image. L'input est une carte de l'image et en sortie on aura une carte.\n",
    "\n",
    "---\n",
    "\n",
    "Deux exemples classique pour interpréter les poolinds:\n",
    "* cas du max:\n",
    "* cas du average pooling: c'est un moyennage pour compter le nb de feature présente dans la région.\n",
    "\n",
    "----\n",
    "Stride du pooling: \n",
    "\n",
    "---\n",
    "\n",
    "qu'est ce que ce pooling va apporter dans les réseaux convolutifs:\n",
    "On rappelle la propriété d'équivariance.\n",
    "\n",
    "---\n",
    "\n",
    "Max pooling et translation invariance\n",
    "\n",
    "C est l'image d'entré, on va lui faire subir une translation de 1 pixel et on considére le max pooling (le carré).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution layer:\n",
    "\n",
    "un tenseur: c'est juste une concaténation de 4 filtres différentes appliqués sur une image, la profondeur est la concaténation des filtres\n",
    "\n",
    "----\n",
    "\n",
    "profondeurs du tenseurs = nombres de filtres\n",
    "\n",
    "----\n",
    "\n",
    "formule de convolution pour des tensuers, on va juste rajouter une somme de plus qui est la profondeur sur laquel on fait le filtrage.\n",
    "\n",
    "----\n",
    "Exemple, pour une image couleur on va avoir un filtre de profondeur 3. \n",
    "\n",
    "----\n",
    "On peut filtrer le tenseur d'entré par plusieurs filtres, avec des coefficients différents\n",
    "\n",
    "---\n",
    "\n",
    "On a quatre filtre qui correspondent à l'image d'entré\n",
    "\n",
    "----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
